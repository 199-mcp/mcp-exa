/**
 * Web Search Tool (v2 - Token-Aware)
 *
 * Enhanced with Context Engineering 2.0 principles:
 * - Token estimation and reporting
 * - Progressive disclosure (caching + retrieval)
 * - Smart defaults to prevent token overflow
 * - Multi-level content detail (summary/standard/full)
 */

import { z } from "zod";
import axios from "axios";
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { API_CONFIG } from "./config.js";
import { ExaSearchRequest, ExaSearchResponse } from "../types.js";
import { createRequestLogger } from "../utils/logger.js";
import { getExaClient } from "../utils/axiosClient.js";
import { formatSearchResponse, formatSingleResult, formatErrorResponse, getTokenManagementGuidance, ContentLevel } from "../utils/responseFormatter.js";
import { resultCache } from "../utils/resultCache.js";
import { calculateMaxCharacters } from "../utils/tokenEstimator.js";

export function registerWebSearchTool(server: McpServer, config?: { exaApiKey?: string }): void {
  // Main search tool with token-aware responses
  server.tool(
    "web_search",
    `Searches the web in real-time with TOKEN-AWARE responses to prevent context overflow.

ðŸŽ¯ WHEN TO USE:
â€¢ Need current information beyond training data
â€¢ Research topics requiring multiple sources
â€¢ Verify facts with recent sources

âš™ï¸ CONTENT LEVELS (choose based on token budget):
â€¢ 'summary' (default)  â†’ ~150 tokens/result | Quick scan, titles + snippets
â€¢ 'standard'          â†’ ~500 tokens/result | Balanced detail, good for exploration
â€¢ 'full'              â†’ ~1500 tokens/result | Complete content, use sparingly

ðŸ’¡ TOKEN MANAGEMENT:
â€¢ Response includes token estimate and cost
â€¢ Results cached for 5 min â†’ request specific results later
â€¢ Use 'summary' first, then request specific results by index
â€¢ IMPORTANT: Responses include metadata to help you manage context

ðŸ“Š RECOMMENDED USAGE:
â€¢ Quick overview: num_results=5-10, content_level='summary' (~1K tokens)
â€¢ Balanced research: num_results=3-5, content_level='standard' (~2K tokens)
â€¢ Deep analysis: num_results=1-3, content_level='full' (~3-5K tokens)

âš ï¸ AVOID TOKEN OVERFLOW:
â€¢ Don't use content_level='full' with num_results>5
â€¢ Monitor token estimate in response metadata
â€¢ Use progressive disclosure (cache_id + result_index) for large result sets`,
    {
      query: z.string().describe("Search query (e.g., 'OpenAI GPT-5 release', 'climate change 2024')"),
      num_results: z.number().optional().describe("Number of results (1-20, default: 3 for 'standard'/'full', 5 for 'summary')"),
      content_level: z.enum(['summary', 'standard', 'full']).optional().describe("Detail level: 'summary'=titles+snippets, 'standard'=moderate, 'full'=complete (default: 'summary')"),
      live_crawl: z.enum(['always', 'auto', 'fallback', 'never']).optional().describe("Content freshness: 'always'=fresh, 'auto'=balanced, 'fallback'=cache first (default: 'auto')"),
      max_chars_per_result: z.number().optional().describe("Max characters per result (overrides content_level defaults, 500-5000)")
    },
    async ({ query, num_results, content_level, live_crawl, max_chars_per_result }) => {
      const requestId = `web_search-${Date.now()}-${Math.random().toString(36).substring(2, 7)}`;
      const logger = createRequestLogger(requestId, 'web_search');

      logger.start(query);

      try {
        // Smart defaults based on content level
        const actualContentLevel: ContentLevel = content_level || 'summary';
        const defaultNumResults = actualContentLevel === 'summary' ? 5 : 3;
        const numResults = num_results || defaultNumResults;

        // Calculate smart max_characters based on token budget
        const maxChars = max_chars_per_result || calculateMaxCharacters(numResults, 20000);

        logger.log(`Content level: ${actualContentLevel}, Results: ${numResults}, MaxChars: ${maxChars}`);

        // Use shared axios client with keep-alive
        const axiosInstance = getExaClient(config);

        const searchRequest: ExaSearchRequest = {
          query,
          type: "auto",
          numResults,
          contents: {
            text: {
              maxCharacters: maxChars
            },
            livecrawl: live_crawl || 'auto'
          }
        };

        logger.log("Sending request to Exa API");

        const response = await axiosInstance.post<ExaSearchResponse>(
          API_CONFIG.ENDPOINTS.SEARCH,
          searchRequest
        );

        logger.log("Received response from Exa API");

        if (!response.data || !response.data.results) {
          logger.log("Warning: Empty or invalid response from Exa API");
          return {
            content: [{
              type: "text" as const,
              text: "No search results found. Please try a different query."
            }]
          };
        }

        logger.log(`Found ${response.data.results.length} results`);

        // Format response with token-awareness
        const formatted = formatSearchResponse(
          response.data,
          query,
          actualContentLevel,
          25000 // Safe limit to prevent 32K overflow
        );

        logger.log(`Formatted response: ~${formatted.metadata.totalTokens} tokens`);

        const result = {
          content: [{
            type: "text" as const,
            text: formatted.text
          }]
        };

        logger.complete();
        return result;

      } catch (error) {
        logger.error(error);

        const errorText = formatErrorResponse(error as Error, query);

        return {
          content: [{
            type: "text" as const,
            text: errorText
          }],
          isError: true,
        };
      }
    }
  );

  // Tool to retrieve specific result from cache
  server.tool(
    "get_search_result",
    `Retrieves a SPECIFIC result from a previous search using progressive disclosure.

ðŸŽ¯ WHEN TO USE:
â€¢ You have a cache_id from a previous web_search
â€¢ Want full content of specific result without loading all results
â€¢ Need to deep-dive into one result while keeping token usage low

ðŸ’¡ PATTERN (Context Engineering):
1. Call web_search with content_level='summary' (low tokens)
2. Identify interesting result by index (0, 1, 2, ...)
3. Call this tool with cache_id + index for full content
4. Saves ~80% tokens vs. requesting all results in 'full' mode

ðŸ“Š TOKEN EFFICIENCY:
â€¢ web_search (5 results, summary): ~750 tokens
â€¢ get_search_result (1 result, full): ~1500 tokens
â€¢ Total: ~2250 tokens vs. ~7500 tokens for all results in full mode`,
    {
      cache_id: z.string().describe("Cache ID from previous web_search response"),
      result_index: z.number().describe("Index of result to retrieve (0-based, shown in search results)")
    },
    async ({ cache_id, result_index }) => {
      const requestId = `get_result-${Date.now()}`;
      const logger = createRequestLogger(requestId, 'get_search_result');

      logger.start(`Cache: ${cache_id}, Index: ${result_index}`);

      try {
        const cached = resultCache.getCachedResults(cache_id);

        if (!cached) {
          return {
            content: [{
              type: "text" as const,
              text: `âŒ Cache not found or expired: ${cache_id}\n\nCaches expire after 5 minutes. Please run web_search again.`
            }],
            isError: true
          };
        }

        const result = resultCache.getResultByIndex(cache_id, result_index);

        if (!result) {
          return {
            content: [{
              type: "text" as const,
              text: `âŒ Invalid result index: ${result_index}\n\nValid range: 0-${cached.totalResults - 1}`
            }],
            isError: true
          };
        }

        const formatted = formatSingleResult(result, result_index, cache_id, cached.totalResults);

        logger.complete();
        return {
          content: [{
            type: "text" as const,
            text: formatted
          }]
        };

      } catch (error) {
        logger.error(error);

        return {
          content: [{
            type: "text" as const,
            text: formatErrorResponse(error as Error)
          }],
          isError: true
        };
      }
    }
  );

  // Tool to get token management guidance
  server.tool(
    "get_token_guidance",
    "Returns comprehensive guidance on managing tokens when using Exa search tools. Use when you need to optimize token usage or understand content level options.",
    {},
    async () => {
      return {
        content: [{
          type: "text" as const,
          text: getTokenManagementGuidance()
        }]
      };
    }
  );
}
